import streamlit as st
import os
from openai import OpenAI
import plotly.graph_objects as go
import json
import base64

# --- Page Config ---
st.set_page_config(
    page_title="AI Speech Coach (Adaptive)",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Sidebar: Settings ---
st.sidebar.title("âš™ï¸ æ¼”è¬›æƒ…å¢ƒè¨­å®š")

personality = st.sidebar.radio(
    "1. æ€§æ ¼è¨­å®š (Personality)",
    options=["I å‹ (å…§å‘/æ²‰ç©©)", "E å‹ (å¤–å‘/ç†±æƒ…)"],
    index=0
)

coaching_style = st.sidebar.selectbox(
    "2. æ•™ç·´é¢¨æ ¼ (Coaching Style)",
    options=["æº«æŸ”é¼“å‹µ (Supportive)", "å¹³è¡¡å›é¥‹ (Balanced)", "åš´æ ¼é­”é¬¼æ•™ç·´ (Strict/Critical)"],
    index=1
)

scenario = st.sidebar.selectbox(
    "3. æ¼”è¬›å ´æ™¯ (Scenario) [é—œéµé‚è¼¯]",
    options=[
        "å­¸ä½å£è©¦/èª²å ‚å ±å‘Š (Thesis Defense/Class Report)",
        "ç§‘æ™®æ¼”è¬›/å…¬çœ¾æ¨å»£ (Public Outreach)",
        "å­¸è¡“ç ”è¨æœƒ (Conference Presentation)"
    ],
    index=0
)

audience = st.sidebar.text_input(
    "4. é è¨­è½çœ¾ (Audience)",
    value="Professors and Graduate Students",
    help="ä¾‹å¦‚: Professors, General Public, High School Students"
)

api_key = st.sidebar.text_input(
    "5. OpenAI API Key",
    type="password"
)

# --- Main Area ---
st.title("ğŸ™ï¸ AI å°ˆæ¥­æ¼”è¬›æ•™ç·´")
st.markdown("---")

uploaded_file = st.file_uploader("ä¸Šå‚³æ‚¨çš„æ¼”è¬›éŒ„éŸ³ (MP3, WAV, M4A)", type=["mp3", "wav", "m4a"])

# --- Analysis Logic ---

def encode_audio(file):
    return base64.b64encode(file.read()).decode("utf-8")

def analyze_audio(client, audio_base64, settings):
    # Construct System Prompt based on Settings
    
    # 1. Personality & Style
    style_instruction = ""
    if "Supportive" in settings['style']:
        style_instruction = "You are a warm, encouraging coach. Focus on potential and strengths mainly. Use gentle language."
    elif "Strict" in settings['style']:
        style_instruction = "You are a very strict, critical coach. Focus on logic holes, weak arguments, and mistakes. Be direct."
    else: # Balanced
        style_instruction = "You are a balanced professional coach. diverse feedback between pros and cons."

    # 2. Scenario specific logic
    opening_instruction = ""
    scenario_type = ""
    if "Thesis Defense" in settings['scenario']:
        scenario_type = "Defense"
        opening_instruction = "For the 'Opening Analysis', focus heavily on **Structure & Problem Statement**. Did the speaker clearly define the research gap? Is the outline logical?"
    elif "Public Outreach" in settings['scenario']:
        scenario_type = "Public"
        opening_instruction = "For the 'Opening Analysis', focus heavily on **The Hook**. Did they grab attention immediately? Was it engaging/fun?"
    else: # Conference
        scenario_type = "Conference"
        opening_instruction = "For the 'Opening Analysis', focus on professional delivery and clarity of contribution."

    # 3. Audience check
    audience_instruction = f"Check if the terminology density is appropriate for this audience: {settings['audience']}."

    system_prompt = f"""
    You are an expert Speech Coach. Output JSON only.
    Language: Traditional Chinese (ç¹é«”ä¸­æ–‡) for all user-facing content.
    
    Settings:
    - Coach Personality: {settings['personality']}
    - Style: {style_instruction}
    - Scenario: {settings['scenario']} ({opening_instruction})
    - Audience: {settings['audience']} ({audience_instruction})

    Analyze the provided audio. Return a JSON object with this exact structure:
    {{
        "summary": {{
            "score": <int 0-100>,
            "wpm": <int>,
            "confidence_level": "<string e.g. High/Medium/Low>"
        }},
        "radar_data": {{
            "professionalism": <int 0-10>,
            "logic_structure": <int 0-10>,
            "vocal_expression": <int 0-10>,
            "time_management": <int 0-10>,
            "audience_fit": <int 0-10>
        }},
        "opening_analysis": {{
            "title": "<string based on scenario e.g. ç ”ç©¶å‹•æ©Ÿèˆ‡æ¶æ§‹æ¸…æ™°åº¦ or é–‹å ´å¸å¼•åŠ›>",
            "content": "<string analysis of the first minute>"
        }},
        "feedback_tabs": {{
            "strengths": ["<string point 1>", "<string point 2>", ...],
            "improvements": ["<string point 1>", "<string point 2>", ...],
            "simulated_qa": ["<string question 1>", "<string question 2>"]
        }}
    }}
    """

    try:
        completion = client.chat.completions.create(
            model="gpt-4o-audio-preview",
            modalities=["text"],
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        { 
                            "type": "input_audio", 
                            "input_audio": { 
                                "data": audio_base64, 
                                "format": "wav" 
                            }
                        }
                    ]
                }
            ]
        )
        return json.loads(completion.choices[0].message.content)
    except Exception as e:
        return {"error": str(e)}

# --- Execution ---

if uploaded_file is not None:
    if st.button("ğŸš€ é–‹å§‹å…¨æ–¹ä½åˆ†æ"):
        if not api_key:
            st.error("è«‹å…ˆè¼¸å…¥ OpenAI API Key ğŸ”‘")
        else:
            with st.spinner("æ­£åœ¨åˆ†ææ‚¨çš„æ¼”è¬› (GPT-4o Audio)..."):
                # Prepare Client
                client = OpenAI(api_key=api_key)
                
                # Audio Processing
                # Note: For simple Streamlit file objects, we can read directly.
                # In a real app, might need to ensure format compatibility.
                # Here we assume the user uploads a compatible format or we send as is (api supports mp3, wav).
                # The format param in input_audio maps to wav/mp3. Let's assume wav for generic bytes or try to detect.
                # For this demo, let's send strictly as 'wav' or 'mp3' based on extension, defaulting to wav.
                file_ext = uploaded_file.name.split('.')[-1].lower()
                audio_format = "mp3" if file_ext == "mp3" else "wav" 
                
                # Encode
                audio_b64 = encode_audio(uploaded_file)
                
                # Analyze
                settings = {
                    "personality": personality,
                    "style": coaching_style,
                    "scenario": scenario,
                    "audience": audience
                }
                
                result = analyze_audio(client, audio_b64, settings)
                
                if "error" in result:
                    st.error(f"Analysis Failed: {result['error']}")
                else:
                    # --- Display Results ---
                    
                    # 1. Summary Metrics
                    c1, c2, c3 = st.columns(3)
                    c1.metric("ç¸½é«”è©•åˆ† (Score)", result['summary']['score'])
                    c2.metric("èªé€Ÿ (WPM)", result['summary']['wpm'])
                    c3.metric("è‡ªä¿¡åº¦", result['summary']['confidence_level'])
                    
                    st.markdown("---")
                    
                    # 2. Radar Chart
                    col_chart, col_opening = st.columns([1, 1])
                    
                    with col_chart:
                        st.subheader("äº”ç¶­é›·é”åˆ†æ")
                        radar_data = result['radar_data']
                        categories = ['å°ˆæ¥­åº¦', 'é‚è¼¯æ¶æ§‹', 'èªæ°£è¡¨é”', 'æ™‚é–“æŒæ§', 'è½çœ¾é©é…åº¦']
                        values = [
                            radar_data['professionalism'],
                            radar_data['logic_structure'],
                            radar_data['vocal_expression'],
                            radar_data['time_management'],
                            radar_data['audience_fit']
                        ]
                        
                        fig = go.Figure(data=go.Scatterpolar(
                            r=values,
                            theta=categories,
                            fill='toself'
                        ))
                        fig.update_layout(
                            polar=dict(
                                radialaxis=dict(
                                    visible=True,
                                    range=[0, 10]
                                )),
                            showlegend=False
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                    with col_opening:
                        st.subheader(f"ğŸ” {result['opening_analysis']['title']}")
                        st.info(result['opening_analysis']['content'])
                    
                    st.markdown("---")
                    
                    # 3. Detailed Tabs
                    tab1, tab2, tab3 = st.tabs(["ğŸŒŸ å„ªé» (Strengths)", "ğŸ’¡ æ”¹é€²å»ºè­° (Improvements)", "â“ æ¨¡æ“¬æå• (Simulated Q&A)"])
                    
                    with tab1:
                        for item in result['feedback_tabs']['strengths']:
                            st.success(f"âœ… {item}")
                            
                    with tab2:
                        for item in result['feedback_tabs']['improvements']:
                            st.warning(f"âš ï¸ {item}")
                            
                    with tab3:
                        st.markdown("### æ¨¡æ“¬æ•™æˆ/è½çœ¾æå•")
                        for i, q in enumerate(result['feedback_tabs']['simulated_qa'], 1):
                            st.markdown(f"**Q{i}:** {q}")
